---
title: 随机变量的数字特征
date: 2024-11-21 14:56:04
categories:
  - note
  - 数一
  - 概率论
tags: [概率论]
index_img:
banner_img: /images/壁纸.jpg
---

## 知识结构
![知识结构](../images/随机变量的数字特征/知识结构.png)

## 数学期望

### 一维随机变量

数学期望条件：记为$EX$或$E(X)$

- 离散型$\sum_{i=1}^{\infty}x_ip_i$绝对收敛，
- 连续性$\int_{-\infty}^{+\infty}xf(x)dx$绝对收敛

方差：$DX=E((X-EX)^2)=E(X^2)-(EX)^2$

![常见一维随机变量分布](../images/随机变量的数字特征/常见一维随机变量分布.png)

&nbsp;&nbsp;&nbsp;&nbsp;$\sum_{t=0}^{\infty}\frac{\lambda ^t}{t!}=e^{\lambda}$

### 二维随机变量

数学期望条件：记为$E(g(X,Y))$

- 离散型，函数$g(x,y)$,$\sum_{j=1}^{\infty}\sum_{i=1}^{\infty}g(x_i,y_i)\cdot p_{ij}$绝对收敛
- 连续性，函数$g(x,y)$,$\int_{-\infty}^{+\infty}g(x,y)\cdot f(x,y)$绝对收敛

![二维连续性期望计算](../images/随机变量的数字特征/二维连续型期望计算.png)

### 性质

- $E(C)=C$
- $E(C\cdot X)=C\cdot E(X)$
- $E(X+C)=E(X)+C$
- $E(X+Y)=E(X)+E(Y)$
- $X,Y$相互独立，$E(X\cdot Y)=E(x)\cdot E(Y)$

## 方差

&nbsp;&nbsp;&nbsp;&nbsp;平方的期望-期望的平方

性质：

- $D(C)=C$
- $D(CX)=C^2D(X)$
- $D(C+X)=D(X)$
- $D(X+Y)=D(X)+D(Y)+2*E([X-E(X)]\cdot [Y-E(Y)])$
- $X,Y$相互独立，$D(X+Y)=D(X)+D(Y)$
- $D(X)=0<==>X以概率为1取常数E(X)$

### 一维随机变量

&nbsp;&nbsp;&nbsp;&nbsp;衡量SB与自身均值的偏离程度，$E([X-E(X)]^2)$的存在,也是一个关于$[X-E(X)]^2$的期望，记为$DX=E[(X-EX)^2]=E(X^2)-(EX)^2$

> $=E(X^2)-E(2\cdot E(X)\cdot E(X))+E((EX)^2)$
> $=E(X^2)-E(X)\cdot E(2X)+E((EX)^2)$
> $=E(X^2)-2E(X)\cdot E(X)+E((EX)^2)$
> $=E(X^2)-(EX)^2$

&nbsp;&nbsp;&nbsp;&nbsp;称$\sqrt{DX}$为X的标准差或者均方差，记为$\sigma(X)$

&nbsp;&nbsp;&nbsp;&nbsp;称随机变量$X^*=\frac{X-EX}{\sqrt{DX}}$为X的标准化随机变量，此时$EX^*=0,DX^*=1$

设$g(x)=[X-E(X)]^2$

- 离散型$\sum_{k=1}^{\infty}[x_k-E(X)]^2\cdot p_k$
- 连续型$\int_{-\infty}^{+\infty}[x-E(X)]^2\cdot f(x)dx$

#### 切比雪夫不等式

&nbsp;&nbsp;&nbsp;&nbsp;$E(X)=\mu,D(X)=\sigma^2$对于任一一个大于0的常数$\epsilon$,$P(|X-\mu|\geq\epsilon)\leq \frac{\sigma^2}{\epsilon^2}$或$P(|X-\mu|< \epsilon)\geq 1-\frac{\sigma^2}{\epsilon^2}$

![切比雪夫证明](../images/随机变量的数字特征/切比雪夫不等式证明过程.png)

&nbsp;&nbsp;&nbsp;&nbsp;当DX越小，$P(|X-\mu|<\epsilon)$越大，表明方差是刻画随机变量与期望值分离程度的量

#### 协方差

&nbsp;&nbsp;&nbsp;&nbsp;$E([X-E(X)]\cdot [Y-E(Y)])$叫做$X与Y$的协方差，记为$Cov(X,Y)$

性质：

- $Cov(X,Y)$=$Cov(Y,X)$
- $Cov(X,X)=E([X-EX]^2)=D(X)$
- $Cov(X,Y)=E(XY)-E(X)E(Y)$
- $Cov(aX,bY)=abCov(X,Y)$
- $Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)$

#### 相关系数

&nbsp;&nbsp;&nbsp;&nbsp;相关系数：$\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{DX}\cdot \sqrt{DY}}$,用来衡量X与Y的线性相关程度

性质：

- $\rho_{XY}\leq 1$
- 若$X,Y$存在线性关系，即Y可由X表示$Y=aX+b(a.b常数且a\neq 0)$,当$a>0$，$\rho_{XY}=1$，当$a<0$，$\rho_{XY}=-1$
- $|\rho_{XY}|$越靠近1，相关性越大，反之相关性越小
- $|\rho_{XY}|=0$，表示$X,Y$不线性相关==不相关 ==不线性相关，不代表独立

### 二维随机变量

